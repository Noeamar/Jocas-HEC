{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee997ee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ea17c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ---------- 1. Load JSONL ----------\n",
    "path = \"/Users/noeamar/Documents/HEC/Jocas-HEC/Data/LLM_labels.jsonl\"\n",
    "\n",
    "records = []\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        try:\n",
    "            records.append(json.loads(line))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(\"Shape initiale :\", df.shape)\n",
    "\n",
    "# ---------- 2. Garder seulement les lignes avec Label_All DICT ----------\n",
    "VALID_LABELS = [\n",
    "    \"DIVERSITY\",\n",
    "    \"REMUNERATION_BENEFITS\",\n",
    "    \"PROFESSIONAL_OPPORTUNITIES\",\n",
    "    \"CULTURE_VALUES\",\n",
    "    \"LEADERSHIP\",\n",
    "    \"WORK_LIFE_BALANCE\",\n",
    "]  # ne pas inclure CONFIDENCE !\n",
    "\n",
    "def extract_labels(d):\n",
    "    if isinstance(d, dict):\n",
    "        if all(k in d for k in VALID_LABELS):\n",
    "            return [d[k] for k in VALID_LABELS]\n",
    "    return None\n",
    "\n",
    "df[\"label_vector\"] = df[\"Label_All\"].apply(extract_labels)\n",
    "df = df[df[\"label_vector\"].notnull()].reset_index(drop=True)\n",
    "print(\"Shape après filtre Label_All :\", df.shape)\n",
    "\n",
    "# ---------- 3. Y : numpy array ----------\n",
    "y = np.vstack(df[\"label_vector\"].values).astype(int)\n",
    "print(\"Y shape :\", y.shape)\n",
    "\n",
    "# ---------- 4. Créer la colonne texte ----------\n",
    "TEXT_COLS = [\n",
    "    \"job_title\",\n",
    "    \"description_job\",\n",
    "    \"description_profil\",\n",
    "    \"description_entreprise\",\n",
    "    \"description_full\",\n",
    "]\n",
    "df[\"text\"] = df[TEXT_COLS].fillna(\"\").agg(\" \".join, axis=1)\n",
    "X_text = df[\"text\"].values\n",
    "\n",
    "# ---------- 5. TF-IDF ----------\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    ")\n",
    "X_vec = vectorizer.fit_transform(X_text)\n",
    "print(\"X_vec shape :\", X_vec.shape)\n",
    "\n",
    "# ---------- 6. Cross-validation stratifiée multi-label ----------\n",
    "strat_target = y.sum(axis=1)\n",
    "strat_target = np.clip(strat_target, 0, 1)  # binaire\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_micro_scores, f1_macro_scores = [], []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, test_idx in kf.split(X_vec, strat_target):\n",
    "    print(f\"\\n===== Fold {fold} =====\")\n",
    "    fold += 1\n",
    "\n",
    "    X_train, X_test = X_vec[train_idx], X_vec[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = MultiOutputClassifier(\n",
    "        XGBClassifier(\n",
    "            n_estimators=200,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric=\"logloss\",\n",
    "            tree_method=\"hist\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1_micro = f1_score(y_test, y_pred, average=\"micro\", zero_division=0)\n",
    "    f1_macro = f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    f1_micro_scores.append(f1_micro)\n",
    "    f1_macro_scores.append(f1_macro)\n",
    "\n",
    "    print(f\"F1-micro: {f1_micro:.4f} | F1-macro: {f1_macro:.4f}\")\n",
    "    print(\"\\nClassification report (fold courant) :\")\n",
    "    print(classification_report(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        target_names=VALID_LABELS,\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "# ---------- 7. Résultats globaux ----------\n",
    "print(\"\\n===== Résumé 5-fold CV =====\")\n",
    "print(f\"F1-micro moyen : {np.mean(f1_micro_scores):.4f}  ± {np.std(f1_micro_scores):.4f}\")\n",
    "print(f\"F1-macro moyen : {np.mean(f1_macro_scores):.4f}  ± {np.std(f1_macro_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
